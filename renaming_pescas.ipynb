{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> <font color = \"bisque\"> Tareas:</font> </u>\n",
    "## <font color = \"bisque\"> * Implementar procesos de renombre en TOPICO PESCAS</font> \n",
    "\n",
    "---\n",
    "\n",
    "<b> <font color = \"LightSalmon\"> MODO DE TRABAJO PROCESO DE RENOMBRE - v2 </font> </b>\n",
    "\n",
    "Voy a trabajar sobre argendata/data que esté hasta ahora, en un fork propio.\n",
    "\n",
    "<b> Sobre argendata/data lo que voy a hacer es tomar los .csv  originales y hacer lo siguiente (dependiendo el caso), generando .csv actualizados:</b>\n",
    "\n",
    "\n",
    "   - Si un dataset tiene un código que esté incluido en los geocodigos del geonomenclador, se nomencla con la string de name_long\n",
    "\n",
    "   - Si un dataset tiene un código que NO este incluido en los geocodigos y tiene una string que matchee sin ambigüedad en desc_fundar, entonces se usa el código que está en el geonomenclador (y se guarda la asociación del codigo encontrado con el codigo usado)\n",
    "\n",
    "   - Si un dataset tiene un código que NO este incluido en los geocodigos y tiene una string que NO matchea sin ambigüedad en desc_fundar, se genera un código nuevo (a revisión para ser desambiguado con posibles matches)\n",
    "\n",
    "   - Si un dataset tiene una string que matchee sin ambigüedad en desc_fundar entonces se usa el código que está en el geonomenclador para esa string\n",
    "\n",
    "   - Si un dataset tiene una string que NO matchee sin ambigüedad en desc_fundar, entonces se genera un código nuevo (a revisión para ser desambiguado con posibles matches)\n",
    "\n",
    "\n",
    "<b> ¿Cómo busco las columnas de interés para esta iteración? </b>\n",
    "- X% (por ejemplo 80%) del contenido de columnas de interés de un .csv de un tópico es parte de alguna de las columnas del geoneomenclador \n",
    "- Por el momento solo código que esté en el geonomenclador en español\n",
    "\n",
    "Observaciones: \n",
    "- PARA ESTE LABURO ARMÉ MI PROPIO BLOQUE DE ENCODERs, DELIMITERs\n",
    "- Para esta versión de la tarea, en principio, solo consideraría contenido en español\n",
    "\n",
    "<b> <font color = \"LightSalmon\"> Productos: \n",
    "- .csv argendata con agregado de columnas para implementar renombres correspondientes\n",
    "- .csv con lo que mencioné antes con .csv de argendata que presentarían problemas </font> </b>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <u> <font color = \"orangered\"> Cómo abrir cada .csv considerando su encoding: </font> </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"gold\"> Cada .csv de Argendata tiene su propio encodings y delimiters </font>. \n",
    "\n",
    "No todos los .csv que contempla Argendata tienen el mismo enconding y delimiter. Por eso antes de comenzar a trabajar voy a armar el siguiente input para la tarea: dataframe que contenga 4 columnas que sean 'TOPICO', 'archivo_csv', 'encoding' y delimiter'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TOPICO                                        archivo_csv    encoding  \\\n",
      "0   PESCAS        31_consumo_per_capita_pescado_anio_pais.csv       utf-8   \n",
      "1   PESCAS  16_valor_cantidad_precio_exportacion_pesquero.csv       ascii   \n",
      "2   PESCAS  01_produccion_pesquera_captura_y_acuicola_por_...       utf-8   \n",
      "3   PESCAS                                22_pbg_pesquero.csv       utf-8   \n",
      "4   PESCAS             04_desembarque_especie_ultimo_anio.csv       ascii   \n",
      "5   PESCAS                      14_evolucion_pib_pesquero.csv       ascii   \n",
      "6   PESCAS  07_acuicultura_produccion_por_pais_ultimo_anio...       utf-8   \n",
      "7   PESCAS  18_valor_precio_cantidad_expo_por_especie_anio...       ascii   \n",
      "8   PESCAS                          11_total_desembarques.csv       ascii   \n",
      "9   PESCAS  09_composicion_consumo_carne_animal_por_tipo_y...       utf-8   \n",
      "10  PESCAS         29_produccion_vs_consumo_pesca_arg_evo.csv       ascii   \n",
      "11  PESCAS              21_acuicultura_produccion_arg_evo.csv       ascii   \n",
      "12  PESCAS                              27_vab_expo_share.csv       ascii   \n",
      "13  PESCAS    03_composicion_exportaciones_pesca_producto.csv       utf-8   \n",
      "14  PESCAS          20_captura_merluza_hubbsi_vs_cmp_anio.csv       ascii   \n",
      "15  PESCAS           30_share_global_expo_pesca_pais_anio.csv       utf-8   \n",
      "16  PESCAS                       28_consumo_pescado_decil.csv       ascii   \n",
      "17  PESCAS          02_complejos_exportadores_ultimo_anio.csv       utf-8   \n",
      "18  PESCAS     15_participacion_complejo_pesquero_en_expo.csv       ascii   \n",
      "19  PESCAS                        12_capturas_grupos_anio.csv       utf-8   \n",
      "20  PESCAS  26_produccion_pesquera_captura_y_acuicola_shar...       ascii   \n",
      "21  PESCAS       05_expo_pesquera_por_especie_ultimo_anio.csv       ascii   \n",
      "22  PESCAS                        13_captura_especie_anio.csv       ascii   \n",
      "23  PESCAS  08_consumo_pescado_mariscos_per_capita_pais_ul...       utf-8   \n",
      "24  PESCAS    23_share_acuicola_total_pesca_por_pais_anio.csv       utf-8   \n",
      "25  PESCAS  25_produccion_pesquera_captura_y_acuicola_mund...       ascii   \n",
      "26  PESCAS                06_desembarques_puertos_totales.csv  ISO-8859-1   \n",
      "\n",
      "   delimiter  \n",
      "0          ,  \n",
      "1          ,  \n",
      "2          ,  \n",
      "3          ,  \n",
      "4          ,  \n",
      "5          ,  \n",
      "6          ,  \n",
      "7          ,  \n",
      "8          ,  \n",
      "9          ,  \n",
      "10         ,  \n",
      "11         ,  \n",
      "12         ,  \n",
      "13         ,  \n",
      "14         ,  \n",
      "15         ,  \n",
      "16         ,  \n",
      "17         ,  \n",
      "18         ,  \n",
      "19         ,  \n",
      "20         ,  \n",
      "21         ,  \n",
      "22         ,  \n",
      "23         ,  \n",
      "24         ,  \n",
      "25         ,  \n",
      "26         ,  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import chardet\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# ruta de tabajo donde estan los topicos con sus csv \n",
    "base_dir = '/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/data_argendata' # '/home/lucia/Desktop/Fundar/Argendata_renaming/data/data_argendata' \n",
    "\n",
    "# lista para recolectar los datos\n",
    "data = []\n",
    "\n",
    "# tamanio del fragmento a leer (en este caso 100000 bytes)\n",
    "sample_size = 100000\n",
    "\n",
    "for topico in os.listdir(base_dir): # ejemplo SEBACO\n",
    "    topico_path = os.path.join(base_dir, topico) #ejemplo /home/lucia/Desktop/Fundar/Argendata_renaming/data/data_argendata/SEBACO\n",
    "\n",
    "    # ignorar archivos sueltos como LICENSE y README.md\n",
    "    if not os.path.isdir(topico_path):\n",
    "        continue\n",
    "\n",
    "    for archivo in os.listdir(topico_path):\n",
    "        if archivo.endswith('.csv'):\n",
    "            archivo_path = os.path.join(topico_path, archivo)\n",
    "\n",
    "            # leer un fragmento del .csv para análisis\n",
    "            with open(archivo_path, 'rb') as f:\n",
    "                raw_sample = f.read(sample_size)\n",
    "\n",
    "            # detectar encoding\n",
    "            encoding_detected = 'utf-8'  # por defecto\n",
    "            try:\n",
    "                encoding_info = chardet.detect(raw_sample)\n",
    "                if encoding_info and encoding_info['encoding']:\n",
    "                    encoding_detected = encoding_info['encoding']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # decodificar el fragmento\n",
    "            try:\n",
    "                sample = raw_sample.decode(encoding_detected, errors = 'replace')\n",
    "            except:\n",
    "                sample = raw_sample.decode('utf-8', errors = 'replace') \n",
    "\n",
    "            # detectar delimitador\n",
    "            delimiter_detected = ','\n",
    "            try:\n",
    "                sniffer = csv.Sniffer()\n",
    "                dialect = sniffer.sniff(sample)\n",
    "                delimiter_detected = dialect.delimiter\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # agregar al resultado\n",
    "            data.append({\n",
    "                'TOPICO': topico,\n",
    "                'archivo_csv': archivo,\n",
    "                'encoding': encoding_detected,\n",
    "                'delimiter': delimiter_detected\n",
    "            })\n",
    "\n",
    "\n",
    "df_resultado = pd.DataFrame(data)\n",
    "df_codificacion = df_resultado\n",
    "\n",
    "print(df_codificacion)\n",
    "\n",
    "# guardar como csv el archivo csvTopicoArgendata_encoding_and_delimiters\n",
    "# path_df_encoding_delimiters = '/home/lucia/Desktop/Fundar/Argendata_renaming/data/'\n",
    "df_codificacion.to_csv('/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/' + 'PESCA_encoding_delimiters.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <u> <font color = \"orangered\">  Tareas concretas del proceso de renaming </font> </u>\n",
    "\n",
    "<b> <font color = \"gold\"> Sobre argendata/data lo que voy a hacer es tomar los .csv  originales y hacer lo siguiente (dependiendo el caso), generando .csv actualizados: </font> </b>\n",
    "\n",
    "   - si un dataset tiene un código que esté incluido en los geocodigos del geonomenclador, se nomencla con la string de name_long (si es que existe), y si no es así se nomencla con la string de desc_fundar correspondiente\n",
    "\n",
    "   - Si un dataset tiene un código que NO este incluido en los geocodigos y tiene una string que matchee sin ambigüedad en desc_fundar, entonces se usa el código que está en el geonomenclador (y se guarda la asociación del codigo encontrado con el codigo usado)\n",
    "\n",
    "   - Si un dataset tiene un código que NO este incluido en los geocodigos y tiene una string que NO matchea sin ambigüedad en desc_fundar, se genera un código nuevo (a revisión para ser desambiguado con posibles matches)\n",
    "\n",
    "   - Si un dataset tiene una string que matchee sin ambigüedad en desc_fundar entonces se usa el código que está en el geonomenclador para esa string\n",
    "\n",
    "   - Si un dataset tiene una string que NO matchee sin ambigüedad en desc_fundar, entonces se genera un código nuevo (a revisión para ser desambiguado con posibles matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color = \"gold\"> Para hacer esto, empecemos por: </font> </b>\n",
    "\n",
    "1. abriría el archivo según su encoding y delimiter dado por df_codificacion \n",
    "\n",
    "2. detectaría si cada .csv de tiene una columna que se corresponda a la columna geocodigo del csv geonomenclador según la siguiente condición: fijarse si, al menos, el 80% de sus filas se encuentra contenida en la columna geocodigo del geonomenclador\n",
    "\n",
    "3. detectaría si cada .csv de tiene una columna que se corresponda a la columna desc_fundar del csv geonomenclador según la siguiente condición: fijarse si, al menos, el 80% de sus filas se encuentra contenida en la columna desc_fundar del geonomenclador\n",
    "\n",
    "4. esta información guardarla en un dataframe llamado columnscsv_Geocodigo_descFundar, con formato de 4 columnas que sean 'TOPICO', 'archivo_csv', 'columna_Geocodigo', 'columna_DescFundar'. Donde sea 'columna_Geocodigo' es el nombre de la columna de dicho cvs que cumple la condición 60% (80%, X%) geocodigo del geonomenclador y 'descFundar' es el nombre de la columna de dicho csv que cumple la condición 60% (80%, X%) desc_fundar del geonomenclador. \n",
    "\n",
    "A la hora de hacer la comparación del 60%:\n",
    "- De la columna analizada la columna, eliminar nulos\n",
    "- normalizar espacios, mayúsculas, tildes, para que casos como los siguientes no rompan el X%: \"NEA \" y \"NEA\" o \"pampeana\" y \"Pampeana\" o \"Córdoba\" y \"Córdoba\" se reconozcan como idénticos\n",
    "\n",
    "<b> <font color = \"bisque\"> Esto resulta en un df con: TOPICO | archivo_csv | columna_Geocodigo | columna_DescFundar </font> </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOPICO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "archivo_csv",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "columna_Geocodigo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "columna_DescFundar",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "51d2da79-dc5a-445a-888e-867ee7416564",
       "rows": [
        [
         "0",
         "PESCAS",
         "31_consumo_per_capita_pescado_anio_pais.csv",
         "iso3",
         "pais"
        ],
        [
         "1",
         "PESCAS",
         "16_valor_cantidad_precio_exportacion_pesquero.csv",
         null,
         null
        ],
        [
         "2",
         "PESCAS",
         "01_produccion_pesquera_captura_y_acuicola_por_pais_ultimo_anio.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "3",
         "PESCAS",
         "22_pbg_pesquero.csv",
         null,
         "provincia"
        ],
        [
         "4",
         "PESCAS",
         "04_desembarque_especie_ultimo_anio.csv",
         null,
         null
        ],
        [
         "5",
         "PESCAS",
         "14_evolucion_pib_pesquero.csv",
         null,
         null
        ],
        [
         "6",
         "PESCAS",
         "07_acuicultura_produccion_por_pais_ultimo_anio.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "7",
         "PESCAS",
         "18_valor_precio_cantidad_expo_por_especie_anio.csv",
         null,
         null
        ],
        [
         "8",
         "PESCAS",
         "11_total_desembarques.csv",
         null,
         null
        ],
        [
         "9",
         "PESCAS",
         "09_composicion_consumo_carne_animal_por_tipo_y_pais_ultimo_anio.csv",
         "iso3",
         "pais"
        ],
        [
         "10",
         "PESCAS",
         "29_produccion_vs_consumo_pesca_arg_evo.csv",
         null,
         null
        ],
        [
         "11",
         "PESCAS",
         "21_acuicultura_produccion_arg_evo.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "12",
         "PESCAS",
         "27_vab_expo_share.csv",
         null,
         null
        ],
        [
         "13",
         "PESCAS",
         "03_composicion_exportaciones_pesca_producto.csv",
         null,
         null
        ],
        [
         "14",
         "PESCAS",
         "20_captura_merluza_hubbsi_vs_cmp_anio.csv",
         null,
         null
        ],
        [
         "15",
         "PESCAS",
         "30_share_global_expo_pesca_pais_anio.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "16",
         "PESCAS",
         "28_consumo_pescado_decil.csv",
         null,
         null
        ],
        [
         "17",
         "PESCAS",
         "02_complejos_exportadores_ultimo_anio.csv",
         null,
         null
        ],
        [
         "18",
         "PESCAS",
         "15_participacion_complejo_pesquero_en_expo.csv",
         null,
         null
        ],
        [
         "19",
         "PESCAS",
         "12_capturas_grupos_anio.csv",
         null,
         null
        ],
        [
         "20",
         "PESCAS",
         "26_produccion_pesquera_captura_y_acuicola_share_arg_evo.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "21",
         "PESCAS",
         "05_expo_pesquera_por_especie_ultimo_anio.csv",
         null,
         null
        ],
        [
         "22",
         "PESCAS",
         "13_captura_especie_anio.csv",
         null,
         null
        ],
        [
         "23",
         "PESCAS",
         "08_consumo_pescado_mariscos_per_capita_pais_ultimo_anio.csv",
         "iso3",
         "pais"
        ],
        [
         "24",
         "PESCAS",
         "23_share_acuicola_total_pesca_por_pais_anio.csv",
         "iso3",
         "pais_nombre"
        ],
        [
         "25",
         "PESCAS",
         "25_produccion_pesquera_captura_y_acuicola_mundial_anio.csv",
         null,
         null
        ],
        [
         "26",
         "PESCAS",
         "06_desembarques_puertos_totales.csv",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 27
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPICO</th>\n",
       "      <th>archivo_csv</th>\n",
       "      <th>columna_Geocodigo</th>\n",
       "      <th>columna_DescFundar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>31_consumo_per_capita_pescado_anio_pais.csv</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>16_valor_cantidad_precio_exportacion_pesquero.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>01_produccion_pesquera_captura_y_acuicola_por_...</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>22_pbg_pesquero.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>provincia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>04_desembarque_especie_ultimo_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>14_evolucion_pib_pesquero.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>07_acuicultura_produccion_por_pais_ultimo_anio...</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>18_valor_precio_cantidad_expo_por_especie_anio...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>11_total_desembarques.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>09_composicion_consumo_carne_animal_por_tipo_y...</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>29_produccion_vs_consumo_pesca_arg_evo.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>21_acuicultura_produccion_arg_evo.csv</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>27_vab_expo_share.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>03_composicion_exportaciones_pesca_producto.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>20_captura_merluza_hubbsi_vs_cmp_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>30_share_global_expo_pesca_pais_anio.csv</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>28_consumo_pescado_decil.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>02_complejos_exportadores_ultimo_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>15_participacion_complejo_pesquero_en_expo.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>12_capturas_grupos_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>26_produccion_pesquera_captura_y_acuicola_shar...</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>05_expo_pesquera_por_especie_ultimo_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>13_captura_especie_anio.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>08_consumo_pescado_mariscos_per_capita_pais_ul...</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>23_share_acuicola_total_pesca_por_pais_anio.csv</td>\n",
       "      <td>iso3</td>\n",
       "      <td>pais_nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>25_produccion_pesquera_captura_y_acuicola_mund...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PESCAS</td>\n",
       "      <td>06_desembarques_puertos_totales.csv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOPICO                                        archivo_csv  \\\n",
       "0   PESCAS        31_consumo_per_capita_pescado_anio_pais.csv   \n",
       "1   PESCAS  16_valor_cantidad_precio_exportacion_pesquero.csv   \n",
       "2   PESCAS  01_produccion_pesquera_captura_y_acuicola_por_...   \n",
       "3   PESCAS                                22_pbg_pesquero.csv   \n",
       "4   PESCAS             04_desembarque_especie_ultimo_anio.csv   \n",
       "5   PESCAS                      14_evolucion_pib_pesquero.csv   \n",
       "6   PESCAS  07_acuicultura_produccion_por_pais_ultimo_anio...   \n",
       "7   PESCAS  18_valor_precio_cantidad_expo_por_especie_anio...   \n",
       "8   PESCAS                          11_total_desembarques.csv   \n",
       "9   PESCAS  09_composicion_consumo_carne_animal_por_tipo_y...   \n",
       "10  PESCAS         29_produccion_vs_consumo_pesca_arg_evo.csv   \n",
       "11  PESCAS              21_acuicultura_produccion_arg_evo.csv   \n",
       "12  PESCAS                              27_vab_expo_share.csv   \n",
       "13  PESCAS    03_composicion_exportaciones_pesca_producto.csv   \n",
       "14  PESCAS          20_captura_merluza_hubbsi_vs_cmp_anio.csv   \n",
       "15  PESCAS           30_share_global_expo_pesca_pais_anio.csv   \n",
       "16  PESCAS                       28_consumo_pescado_decil.csv   \n",
       "17  PESCAS          02_complejos_exportadores_ultimo_anio.csv   \n",
       "18  PESCAS     15_participacion_complejo_pesquero_en_expo.csv   \n",
       "19  PESCAS                        12_capturas_grupos_anio.csv   \n",
       "20  PESCAS  26_produccion_pesquera_captura_y_acuicola_shar...   \n",
       "21  PESCAS       05_expo_pesquera_por_especie_ultimo_anio.csv   \n",
       "22  PESCAS                        13_captura_especie_anio.csv   \n",
       "23  PESCAS  08_consumo_pescado_mariscos_per_capita_pais_ul...   \n",
       "24  PESCAS    23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
       "25  PESCAS  25_produccion_pesquera_captura_y_acuicola_mund...   \n",
       "26  PESCAS                06_desembarques_puertos_totales.csv   \n",
       "\n",
       "   columna_Geocodigo columna_DescFundar  \n",
       "0               iso3               pais  \n",
       "1               None               None  \n",
       "2               iso3        pais_nombre  \n",
       "3               None          provincia  \n",
       "4               None               None  \n",
       "5               None               None  \n",
       "6               iso3        pais_nombre  \n",
       "7               None               None  \n",
       "8               None               None  \n",
       "9               iso3               pais  \n",
       "10              None               None  \n",
       "11              iso3        pais_nombre  \n",
       "12              None               None  \n",
       "13              None               None  \n",
       "14              None               None  \n",
       "15              iso3        pais_nombre  \n",
       "16              None               None  \n",
       "17              None               None  \n",
       "18              None               None  \n",
       "19              None               None  \n",
       "20              iso3        pais_nombre  \n",
       "21              None               None  \n",
       "22              None               None  \n",
       "23              iso3               pais  \n",
       "24              iso3        pais_nombre  \n",
       "25              None               None  \n",
       "26              None               None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# funcion para eliminar tildes\n",
    "def sin_tildes(s):\n",
    "    nkfd = unicodedata.normalize('NFKD', s)\n",
    "    return ''.join(c for c in nkfd if not unicodedata.combining(c))\n",
    "\n",
    "# rutas y dataframes necesarios\n",
    "\n",
    "base_dir =  '/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/data_argendata' \n",
    "df_geonomenclador = pd.read_csv('/home/capuccino/Desktop/TrabajoFundar/Argendata_renaming/data/input' + '/geonomenclador_LuloTest.csv')\n",
    "\n",
    "# sets normalizados de las columnas de interes del geonomenclador: geocodigo y desc_fundar \n",
    "# estoy probndo usar set para practicar, si es necesario paso a lista\n",
    "set_geocod = set(\n",
    "    df_geonomenclador['geocodigo']\n",
    "      .dropna().astype(str) #elimino nulos\n",
    "      .str.strip() # quitar espacios al inicio/final\n",
    "      .str.upper() # pasar todo a mayusculas\n",
    "      .apply(sin_tildes) # sacar tildes\n",
    ")\n",
    "set_desc = set(\n",
    "    df_geonomenclador['desc_fundar']\n",
    "      .dropna().astype(str)\n",
    "      .str.strip()\n",
    "      .str.upper()\n",
    "      .apply(sin_tildes)\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "# los topicos (directorios) ignorando los archivos LICENSE y README.md\n",
    "topics = []\n",
    "for d in os.listdir(base_dir):\n",
    "    item_path = os.path.join(base_dir, d)\n",
    "    \n",
    "    if os.path.isdir(item_path): # verifico que sea un directorio\n",
    "        \n",
    "        if d != 'LICENSE' and d != 'README.md':\n",
    "            topics.append(d)\n",
    "\n",
    "for topico in topics:\n",
    "    topic_dir = os.path.join(base_dir, topico)\n",
    "    # listo los .csv de este tópico\n",
    "    csv_files = [f for f in os.listdir(topic_dir) if f.endswith('.csv')]\n",
    "    for archivo in csv_files:\n",
    "        # uso el encoding y delimiter de df_codificacion\n",
    "        row = df_codificacion[\n",
    "            (df_codificacion['TOPICO'] == topico) &\n",
    "            (df_codificacion['archivo_csv'] == archivo)\n",
    "        ]\n",
    "        if row.empty:\n",
    "            print(f'No hay info de encoding/delimiter para {topico}/{archivo}') # quiero probar no estar pifiando\n",
    "            continue\n",
    "        encoding  = row.iloc[0]['encoding']\n",
    "        delimiter = row.iloc[0]['delimiter']\n",
    "        path_csv  = os.path.join(topic_dir, archivo)\n",
    "\n",
    "        # leo csv con el encoding delimiter\n",
    "        try:\n",
    "            df_csv = pd.read_csv(path_csv, encoding = encoding, delimiter = delimiter)\n",
    "        except Exception as e: \n",
    "            print(f'Error leyendo {path_csv}: {e}') # imprimo el error\n",
    "            continue\n",
    "\n",
    "        col_geocod = None\n",
    "        col_desc   = None\n",
    "\n",
    "        # analizar cada columna del .csv\n",
    "        for col in df_csv.columns:\n",
    "            serie = (\n",
    "                df_csv[col]\n",
    "                  .dropna().astype(str)\n",
    "                  .str.strip()\n",
    "                  .str.upper()\n",
    "                  .apply(sin_tildes)\n",
    "            )\n",
    "            n = len(serie)\n",
    "            if n == 0:\n",
    "                continue\n",
    "\n",
    "            match_geo  = serie.isin(set_geocod).sum() / n\n",
    "            match_desc = serie.isin(set_desc).sum()   / n\n",
    "\n",
    "            if match_geo  >= 0.6 and col_geocod is None:\n",
    "                col_geocod = col\n",
    "            if match_desc >= 0.6 and col_desc   is None:\n",
    "                col_desc = col\n",
    "\n",
    "        results.append({\n",
    "            'TOPICO': topico,\n",
    "            'archivo_csv': archivo,\n",
    "            'columna_Geocodigo': col_geocod,\n",
    "            'columna_DescFundar': col_desc\n",
    "        })\n",
    "\n",
    "# creo df de interes\n",
    "columnscsv_Geocodigo_descFundar = pd.DataFrame(results)\n",
    "\n",
    "columnscsv_Geocodigo_descFundar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "geocodigo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "desc_fundar",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "name_long",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "name_short",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Unnamed: 4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unnamed: 5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unnamed: 6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Unnamed: 7",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f5ad7ebf-7333-4385-a422-3009d6888f20",
       "rows": [
        [
         "0",
         "ABW",
         "Aruba",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "AFE",
         "África Oriental y Meridional",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "AFG",
         "Afganistán",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "AFW",
         "África Occidental y Central",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "AGO",
         "Angola",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "AIA",
         "Anguila",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "ALA",
         "Islas Åland",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "ALB",
         "Albania",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "8",
         "AND",
         "Andorra",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "ANT",
         "Antillas Holandesas",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "ARB",
         "Mundo Árabe",
         "Mundo árabe",
         "Mundo árabe",
         null,
         null,
         null,
         " "
        ],
        [
         "11",
         "ARE",
         "Emiratos Árabes Unidos",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "12",
         "ARG",
         "Argentina",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "ARM",
         "Armenia",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "ASM",
         "Samoa Americana",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "ATA",
         "Antártida",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "ATF",
         "Territorio de las Tierras Australes Francesas",
         "Tierras Australes Francesas",
         "Tierras Australes Francesas",
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "ATG",
         "Antigua y Barbuda",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "AUS",
         "Australia",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "AUT",
         "Austria",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "AZE",
         "Azerbaiyán",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "BAT",
         "Territorio Antártico Británico",
         "Antártida Británica",
         "Antártida Británica",
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "BDI",
         "Burundi",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "BEL",
         "Bélgica",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "BEN",
         "Benin",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "BES",
         "Bonaire, San Eustaquio y Saba",
         "Bonaire",
         "Bonaire",
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "BFA",
         "Burkina Faso",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "BGD",
         "Bangladesh",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "BGR",
         "Bulgaria",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "BHR",
         "Bahrein",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "BHS",
         "Bahamas",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "BIH",
         "Bosnia y Herzegovina",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "BLM",
         "San Barthélemy",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "33",
         "BLR",
         "Belarús",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "34",
         "BLX",
         "Bélgica-Luxemburgo",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "BLZ",
         "Belice",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "BMU",
         "Bermuda",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "BOL",
         "Bolivia",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "BRA",
         "Brasil",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "BRB",
         "Barbados",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "BRN",
         "Brunei Darussalam",
         "Brunei",
         "Brunei",
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "BTN",
         "Bhután",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "BVT",
         "Isla Bouvet",
         "Bouvet",
         "Bouvet",
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "BWA",
         "Botswana",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "CAF",
         "República Centroafricana",
         "Rep. Centroafricana",
         "Rep. Centroafricana",
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "CAN",
         "Canadá",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "CCK",
         "Islas Cocos (Keeling)",
         "Islas Cocos",
         "Islas Cocos",
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "CEB",
         "Europa Central y Los Países Bálticos",
         "Europa Central y Bálticos",
         "Europa Central y Bálticos",
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "CEM",
         "Comunidad Económica y Monetaria de Africa Central (CEMAC)",
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "CHE",
         "Suiza",
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 1024
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geocodigo</th>\n",
       "      <th>desc_fundar</th>\n",
       "      <th>name_long</th>\n",
       "      <th>name_short</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFE</td>\n",
       "      <td>África Oriental y Meridional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afganistán</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFW</td>\n",
       "      <td>África Occidental y Central</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>DESHUM_AHDI.WOF</td>\n",
       "      <td>Ramificaciones de Occidente (AHDI)</td>\n",
       "      <td>Ramificaciones de Occidente</td>\n",
       "      <td>Ramificaciones de Occidente</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>NIR</td>\n",
       "      <td>Irlanda del Norte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>CAMCLI_IA</td>\n",
       "      <td>Aviación internacional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>F_ESTPRO</td>\n",
       "      <td>África (OECD)</td>\n",
       "      <td>África</td>\n",
       "      <td>África</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>NAFTA_ESTPRO</td>\n",
       "      <td>Países miembros del NAFTA (OECD)</td>\n",
       "      <td>Países miembros del NAFTA</td>\n",
       "      <td>Países miembros del NAFTA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            geocodigo                         desc_fundar  \\\n",
       "0                 ABW                               Aruba   \n",
       "1                 AFE        África Oriental y Meridional   \n",
       "2                 AFG                          Afganistán   \n",
       "3                 AFW         África Occidental y Central   \n",
       "4                 AGO                              Angola   \n",
       "...               ...                                 ...   \n",
       "1019  DESHUM_AHDI.WOF  Ramificaciones de Occidente (AHDI)   \n",
       "1020              NIR                   Irlanda del Norte   \n",
       "1021        CAMCLI_IA              Aviación internacional   \n",
       "1022         F_ESTPRO                       África (OECD)   \n",
       "1023     NAFTA_ESTPRO    Países miembros del NAFTA (OECD)   \n",
       "\n",
       "                        name_long                   name_short  Unnamed: 4  \\\n",
       "0                             NaN                          NaN         NaN   \n",
       "1                             NaN                          NaN         NaN   \n",
       "2                             NaN                          NaN         NaN   \n",
       "3                             NaN                          NaN         NaN   \n",
       "4                             NaN                          NaN         NaN   \n",
       "...                           ...                          ...         ...   \n",
       "1019  Ramificaciones de Occidente  Ramificaciones de Occidente         NaN   \n",
       "1020                          NaN                          NaN         NaN   \n",
       "1021                          NaN                          NaN         NaN   \n",
       "1022                       África                       África         NaN   \n",
       "1023    Países miembros del NAFTA    Países miembros del NAFTA         NaN   \n",
       "\n",
       "      Unnamed: 5  Unnamed: 6 Unnamed: 7  \n",
       "0            NaN         NaN        NaN  \n",
       "1            NaN         NaN        NaN  \n",
       "2            NaN         NaN        NaN  \n",
       "3            NaN         NaN        NaN  \n",
       "4            NaN         NaN        NaN  \n",
       "...          ...         ...        ...  \n",
       "1019         NaN         NaN        NaN  \n",
       "1020         NaN         NaN        NaN  \n",
       "1021         NaN         NaN        NaN  \n",
       "1022         NaN         NaN        NaN  \n",
       "1023         NaN         NaN        NaN  \n",
       "\n",
       "[1024 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geonomenclador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font color = \"gold\"> Continuamos con lo que enumero a continuación para cumplir las condiciones detalladas enteriormente (los 5 bullets de más arriba): </font> </b>\n",
    "\n",
    "Ya generamos el df columnscsv_Geocodigo_descFundar con: TOPICO | archivo_csv | columna_Geocodigo | columna_DescFundar, \n",
    "Donde 'columna_Geocodigo' es el nombre de la columna de dicho cvs que cumple la condición X% geocodigo del geonomenclador y 'descFundar' es el nombre de la columna de dicho csv que cumple la condición X% desc_fundar del geonomenclador.\n",
    "\n",
    "<b> <font color = \"gold\">Por cada tópico (carpeta) y cada csv dentro de este, busco generar una nueva carpeta de cada tópico y dentro de cada carpeta guardar una copia de sus respectivos csvs pero agregandoles a los mismos dos columnas: una que sea 'geocodigoFundar' y otra que sea 'geonombreFundar'.</font> </b>\n",
    "\n",
    "Si para un csv de un topico tanto columna_Geocodigo como columna_DescFundar es NA, ya sabremos que el csv copia se guardará con NA tanto en las columnas 'geocodigoFundar' como 'geonombreFundar'.\n",
    "\n",
    "Siendo que columnscsv_Geocodigo_descFundar ya tiene por cada tópico y csv, si dicho csv tiene una columna 'columna_Geocodigo' que sería de geocodigo (condicion X% de columna geocodigo del df_geonomenclador) y otra columna 'columna_DescFundar' (condicion del 80 % de la columna desc_fundar del df_geonomenclador), voy a usarcolumnscsv_Geocodigo_descFundar para completar 'geocodigoFundar' y 'geonombreFundar'.\n",
    "\n",
    "Para rellenar las columnas 'geocodigoFundar' y 'geonombreFundar', hay que tener las siguientes consideraciones:\n",
    "\n",
    "- Si un dataset (cada csv original de cada topico) tiene una columna asociada a geocodigo segun columnscsv_Geocodigo_descFundar, el contenido de la columna geocodigoFundar del csv copia tendrá el contenido de la columna asociada a geocodigo segun columnscsv_Geocodigo_descFundar. La columna geonombreFundar del csv copia llenará cada una de sus filas acorde al name_long (si es que existe), y si no es así al string de desc_fundar correspondiente a ese geocodigo del geonomenclador.\n",
    "\n",
    "- Si un dataset tiene una string que matchee sin ambigüedad en desc_fundar del geonomenclador entonces se usa el código que está en el geonomenclador para esa string. Similar al caso anterior.\n",
    "\n",
    "- En el caso de que un dataset tiene un código que NO esté incluido en los geocodigos pero tiene una string que matchee sin ambigüedad en desc_fundar, entonces se usa el código que está en geocódigo en el geonomenclador. Esto se registrará en df_problemas con las columnas TOPICO | csv | problema: \"dataset tiene el codigo [...], que NO esta incluido en los geocodigos pero tiene la string [...] que matchea sin ambiguedad en desc_fundar. No hay que modificar geonomenclador.\". Por cada problema se guarda la string y el código correspondiente. Esto puede dar lugar que un mismo csv de un tópico tenga varios problemas a registrar. NO HAY QUE MODIFICAR GEONOMENCLADOR, EL RENAMING ES HECHO A PARTIR DE LA COLUMNA desc_fundar DEL GEONOMENCLADOR. \n",
    "\n",
    "- Si un dataset tiene un código que NO este incluido en los geocodigos y tiene una string que NO matchea sin ambigüedad en desc_fundar, se genera un código nuevo. Esto se registrará en df_problemas con las columnas TOPICO | csv | problema: \"dataset tiene el codigo [...] que NO esta incluido en los geocodigos y tiene la string [...] que NO matchea sin ambiguedad en desc_fundar. Puede implicar modificaciones del geonomenclador (a revisión, para no pisarse con otros casos).\". Por cada problema se guarda la string y el código correspondiente. Esto puede dar lugar que un mismo csv de un tópico tenga varios problemas a registrar. PODRÍA DAR LUGAR A MODIFICACIONES DEL GEONOMENCLADOR. \n",
    "\n",
    "    -Situacion similar a esta: Dataset tiene el código [...] que NO está incluido en los geocódigos y no existe columna desc_fundar. En df_problemas se reporta: \"dataset tiene el codigo [...] que NO esta incluido en los geocodigos y no existe columna desc_fundar. Puede implicar modificaciones del geonomenclador (a revisión, para no pisarse con otros casos).\"\n",
    "\n",
    "- Si un dataset tiene una string que NO matchee sin ambigüedad en desc_fundar, entonces guardar este caso en el dataframe llamado df_problemas con las columnas TOPICO | csv | problema, donde TOPICO es el topico con el que se corresponde, csv el csv evaluado y en problema poner: \"Para la string [...] se debería generar un codigo nuevo (a revisión, para no pisarse con otros casos)\". PODRÍA DAR LUGAR A MODIFICACIONES DEL GEONOMENCLADOR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TOPICO                                              csv  \\\n",
      "0    PESCAS      31_consumo_per_capita_pescado_anio_pais.csv   \n",
      "1    PESCAS      31_consumo_per_capita_pescado_anio_pais.csv   \n",
      "2    PESCAS      31_consumo_per_capita_pescado_anio_pais.csv   \n",
      "3    PESCAS      31_consumo_per_capita_pescado_anio_pais.csv   \n",
      "4    PESCAS      31_consumo_per_capita_pescado_anio_pais.csv   \n",
      "..      ...                                              ...   \n",
      "248  PESCAS  23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
      "249  PESCAS  23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
      "250  PESCAS  23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
      "251  PESCAS  23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
      "252  PESCAS  23_share_acuicola_total_pesca_por_pais_anio.csv   \n",
      "\n",
      "                                              problema  \n",
      "0    dataset tiene el codigo 'F5503', que NO esta i...  \n",
      "1    dataset tiene el codigo 'F5503', que NO esta i...  \n",
      "2    dataset tiene el codigo 'F5503', que NO esta i...  \n",
      "3    dataset tiene el codigo 'F5503', que NO esta i...  \n",
      "4    dataset tiene el codigo 'F5503', que NO esta i...  \n",
      "..                                                 ...  \n",
      "248  dataset tiene el codigo 'EAZ' que NO esta incl...  \n",
      "249  dataset tiene el codigo 'EAZ' que NO esta incl...  \n",
      "250  dataset tiene el codigo 'EAZ' que NO esta incl...  \n",
      "251  dataset tiene el codigo 'YUG' que NO esta incl...  \n",
      "252  dataset tiene el codigo 'YUG' que NO esta incl...  \n",
      "\n",
      "[253 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# funcion eliminar tildes\n",
    "def sin_tildes(s):\n",
    "    nkfd = unicodedata.normalize('NFKD', s)\n",
    "    return \"\".join(c for c in nkfd if not unicodedata.combining(c))\n",
    "\n",
    "# rutas\n",
    "base_dir = '/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/data_argendata'\n",
    "dest_dir = '/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/data_argendata_new'\n",
    "\n",
    "# df inputs\n",
    "df_cod = df_codificacion\n",
    "df_geo = df_geonomenclador\n",
    "df_cols = columnscsv_Geocodigo_descFundar  \n",
    "\n",
    "# dicc de name_long y desc_fundar por geocodigo del geonomenclador argendata\n",
    "geonames_by_geocode = {}\n",
    "for _, row in df_geonomenclador.iterrows():\n",
    "    raw_code   = str(row['geocodigo'])\n",
    "    code_norm  = sin_tildes(raw_code.strip().upper())\n",
    "    name_long  = row['name_long']\n",
    "    desc_fund  = row['desc_fundar']\n",
    "    geonames_by_geocode[code_norm] = (name_long, desc_fund)\n",
    "\n",
    "# lista problemas por tipo\n",
    "problemas = []\n",
    "\n",
    "# lista de topicos (en este caso es solo pesca)\n",
    "topics = []\n",
    "for d in os.listdir(base_dir):\n",
    "    path = os.path.join(base_dir, d)\n",
    "    if os.path.isdir(path) and d not in ('LICENSE', 'README.md'):\n",
    "        topics.append(d)\n",
    "\n",
    "# proceso cada topico y csv\n",
    "for topico in topics:\n",
    "    src_topic = os.path.join(base_dir, topico)\n",
    "    dst_topic = os.path.join(dest_dir, topico)\n",
    "    os.makedirs(dst_topic, exist_ok = True)\n",
    "    \n",
    "    # listar los archivos csv en este tópico\n",
    "    for archivo in os.listdir(src_topic):\n",
    "        if not archivo.lower().endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        # abro el csv con respectivos encoding y delimiter, cfg de configuracion \n",
    "        cfg = df_codificacion[\n",
    "            (df_codificacion['TOPICO'] == topico) &\n",
    "            (df_codificacion['archivo_csv'] == archivo)\n",
    "        ]\n",
    "        if cfg.empty:\n",
    "            print(f\"No hay info encoding/delimiter para {topico}/{archivo}\")\n",
    "            continue\n",
    "        encoding = cfg.iloc[0]['encoding']\n",
    "        delimiter = cfg.iloc[0]['delimiter']\n",
    "        \n",
    "        # del df columnscsv_Geocodigo_descFundar toma la info del csv y topico que me interesa\n",
    "        row_cols = columnscsv_Geocodigo_descFundar[\n",
    "            (columnscsv_Geocodigo_descFundar['TOPICO'] == topico) &\n",
    "            (columnscsv_Geocodigo_descFundar['archivo_csv'] == archivo)\n",
    "        ]\n",
    "        col_code = row_cols.iloc[0]['columna_Geocodigo'] if not row_cols.empty else None\n",
    "        col_desc = row_cols.iloc[0]['columna_DescFundar'] if not row_cols.empty else None\n",
    "        \n",
    "        # leo csv\n",
    "        src_path = os.path.join(src_topic, archivo)\n",
    "        df = pd.read_csv(src_path, encoding = encoding, delimiter = delimiter)\n",
    "        \n",
    "        # le sumo al csv las nuevas columnas de interes\n",
    "        df['geocodigoFundar'] = pd.NA\n",
    "        df['geonombreFundar'] = pd.NA\n",
    "        \n",
    "        # recorrer filas del csv\n",
    "        for idx in df.index:\n",
    "\n",
    "            # CASO A: existe columna correspondiente a geocodigo del geonomenclador en el csv\n",
    "\n",
    "            # A.0) hay un codigo presente en geocodigos, lo relleno con name_long o desc_fundar\n",
    "            \n",
    "            if pd.notna(col_code):\n",
    "                raw_code = str(df.at[idx, col_code])\n",
    "                norm_code = sin_tildes(raw_code.strip().upper())\n",
    "                if norm_code in geonames_by_geocode:\n",
    "                    nl, desc0 = geonames_by_geocode[norm_code]\n",
    "                    df.at[idx, 'geocodigoFundar'] = norm_code\n",
    "                    df.at[idx, 'geonombreFundar'] = nl if pd.notna(nl) else desc0 # relleno con name_long si existe, sino relleno con la sting de desc_fundar\n",
    "                else:\n",
    "                    # A.1) hay un codigo NO presente en geocodigos, pero intento por columna desc_fundar\n",
    "                    if pd.notna(col_desc):\n",
    "                        raw_desc = str(df.at[idx, col_desc])\n",
    "                        norm_desc = sin_tildes(raw_desc.strip().upper()) # normalizo columna del csv de interes que se corresponderia a desc_fundar segun condicion del X%\n",
    "                        # bsqueda de coincidencias en desc_fundar\n",
    "                        matched_code = []\n",
    "                        for code_key, (_nl, desc0) in geonames_by_geocode.items(): # _nl para hacer explicito que no uso nl en este caso\n",
    "                            norm_desc0 = sin_tildes(str(desc0).strip().upper()) # normalizo desc_fundar del geonomenclador \n",
    "                            #(para comparacion con la columna del csv de interes columna del csv de interes que se corresponderia a desc_fundar segun condicion del X%)\n",
    "                            if norm_desc0 == norm_desc:\n",
    "                                matched_code.append(code_key)\n",
    "                        if len(matched_code) == 1:\n",
    "                            c0 = matched_code[0]\n",
    "                            nl, desc0 = geonames_by_geocode[c0]\n",
    "                            df.at[idx, 'geocodigoFundar'] = c0\n",
    "                            df.at[idx, 'geonombreFundar'] = nl if pd.notna(nl) else desc0\n",
    "                            problemas.append({\n",
    "                                'TOPICO': topico,\n",
    "                                'csv': archivo,\n",
    "                                'problema': f\"dataset tiene el codigo '{norm_code}', que NO esta incluido en los geocodigos pero tiene la string '{norm_desc}' que matchea sin ambiguedad en desc_fundar. No hay que modificar geonomenclador.\"\n",
    "                            })\n",
    "                        else:\n",
    "                            problemas.append({\n",
    "                                'TOPICO': topico,\n",
    "                                'csv': archivo,\n",
    "                                'problema': f\"dataset tiene el codigo '{norm_code}' que NO esta incluido en los geocodigos y tiene la string '{norm_desc}' que NO matchea sin ambiguedad en desc_fundar. Puede implicar modificaciones del geonomenclador (a revisión, para no pisarse con otros casos).\"\n",
    "                            })\n",
    "                    # A.2) no hay columna desc_fundar para intentar\n",
    "\n",
    "                    else:\n",
    "                        problemas.append({\n",
    "                            'TOPICO': topico,\n",
    "                            'csv': archivo,\n",
    "                            'problema': f\"dataset tiene el codigo '{norm_code}' que NO esta incluido en los geocodigos y no existe columna desc_fundar. Puede implicar modificaciones del geonomenclador (a revisión, para no pisarse con otros casos).\"\n",
    "                        })\n",
    "            \n",
    "            # CASO B: no existe columna de geocodigo, pero si se tiene de desc_fundar\n",
    "\n",
    "            elif pd.notna(col_desc):\n",
    "                raw_desc = str(df.at[idx, col_desc])\n",
    "                norm_desc = sin_tildes(raw_desc.strip().upper())\n",
    "                matched_code = []\n",
    "                for code_key, (_nl, desc0) in geonames_by_geocode.items():\n",
    "                    if sin_tildes(str(desc0).strip().upper()) == norm_desc:\n",
    "                        matched_code.append(code_key)\n",
    "                if len(matched_code) == 1:\n",
    "                    c0 = matched_code[0]\n",
    "                    nl, desc0 = geonames_by_geocode[c0]\n",
    "                    df.at[idx, 'geocodigoFundar'] = c0\n",
    "                    df.at[idx, 'geonombreFundar'] = nl if pd.notna(nl) else desc0\n",
    "                else:\n",
    "                    problemas.append({\n",
    "                        'TOPICO': topico,\n",
    "                        'csv': archivo,\n",
    "                        'problema': f\"Para la string '{norm_desc}' se debería generar un codigo nuevo. Puede implicar modificaciones del geonomenclador (a revisión, para no pisarse con otros casos).\"\n",
    "                    })\n",
    "            \n",
    "            # CASO C: si no hay columnas asociadas, quedan NaN\n",
    "        \n",
    "        # guardar csv copia modificado en su correspondiente topico, con UTF-8 y separador coma\n",
    "        dst_path = os.path.join(dest_dir, topico, archivo)\n",
    "        df.to_csv(dst_path, index = False,  encoding = 'utf-8', sep = ',')\n",
    "\n",
    "# df de problemas\n",
    "df_problemas = pd.DataFrame(problemas)\n",
    "df_problemas.to_csv('/home/capuccino/Desktop/TrabajoFundar/pesca_renaming/df_problemas.csv', index = False,  encoding = 'utf-8', sep = ',')\n",
    "print(df_problemas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
